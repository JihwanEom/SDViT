Environment:
	Python: 3.8.13
	PyTorch: 1.8.1+cu111
	Torchvision: 0.9.1+cu111
	CUDA: 11.1
	CUDNN: 8005
	NumPy: 1.23.3
	PIL: 9.2.0
Args:
	algorithm: ERM_ViT
	checkpoint_freq: None
	data_dir: ./domainbed/data/
	dataset: PACS
	holdout_fraction: 0.2
	hparams: {"backbone":"DeitSmall","batch_size":32,"lr":5e-05,"resnet_dropout":0.0,"weight_decay":0.0,"CutMix":"True"}
	hparams_seed: 0
	output_dir: ./domainbed/PACS/ERM_ViT_Deit-S/CutMix/20ae49dffb99e43e611636e8305d5824
	save_best_model: True
	save_model_every_checkpoint: False
	seed: 2073780886
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [1]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	CutMix: True
	EMA: False
	EMA_decay: 0.999
	backbone: DeitSmall
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 5e-05
	nonlinear_classifier: False
	resnet18: False
	resnet_dropout: 0.0
	test_env: [1]
	weight_decay: 0.0
device: cuda
Best model upto now
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  epoch         loss          mem_gb        step          step_time    
0.1683953630  0.1491442543  0.1332622601  0.1517094017  0.3293413174  0.2904191617  0.2360050891  0.2254777070  0.0000000000  2.0962579250  7.7879266739  0             0.7147998810 
Best model upto now
0.9823062843  0.9511002445  0.7990405117  0.8055555556  1.0000000000  0.9850299401  0.9554707379  0.9210191083  7.1856287425  0.6171064864  8.0368371010  300           0.3634732993 
Best model upto now
0.9932885906  0.9657701711  0.7921108742  0.8055555556  1.0000000000  0.9760479042  0.9605597964  0.9261146497  14.371257485  0.3887465725  8.0384087563  600           0.4791777666 
Best model upto now
0.9993898719  0.9706601467  0.8113006397  0.8311965812  1.0000000000  0.9880239521  0.9891857506  0.9528662420  21.556886227  0.3762705796  8.0384087563  900           0.5120463300 
0.9975594875  0.9633251834  0.7953091684  0.8247863248  1.0000000000  0.9820359281  0.9898218830  0.9554140127  28.742514970  0.3501730358  8.0384087563  1200          0.5209449275 
0.9975594875  0.9682151589  0.8304904051  0.8333333333  1.0000000000  0.9880239521  0.9939567430  0.9515923567  35.928143712  0.3171760145  8.0384087563  1500          0.5327449862 
Best model upto now
0.9987797437  0.9584352078  0.8336886994  0.8547008547  1.0000000000  0.9850299401  0.9949109415  0.9694267516  43.113772455  0.3594205897  8.0384087563  1800          0.5310099753 
0.9987797437  0.9706601467  0.8272921109  0.8547008547  1.0000000000  0.9880239521  0.9936386768  0.9515923567  50.299401197  0.3265371219  8.0384087563  2100          0.5274741936 
Best model upto now
0.9993898719  0.9779951100  0.8097014925  0.8333333333  1.0000000000  0.9880239521  0.9980916031  0.9732484076  57.485029940  0.2983041642  8.0384087563  2400          0.5294274267 
1.0000000000  0.9779951100  0.8065031983  0.8376068376  0.9992514970  0.9850299401  0.9971374046  0.9643312102  64.670658682  0.3091489365  8.0397667885  2700          0.5471170036 
1.0000000000  0.9804400978  0.8251599147  0.8482905983  1.0000000000  0.9880239521  0.9968193384  0.9643312102  71.856287425  0.3128104517  8.0397667885  3000          0.5493954031 
1.0000000000  0.9633251834  0.8107675906  0.8354700855  1.0000000000  0.9850299401  0.9984096692  0.9630573248  79.041916167  0.3020584394  8.0397667885  3300          0.5472912963 
1.0000000000  0.9731051345  0.8411513859  0.8675213675  1.0000000000  0.9730538922  0.9965012723  0.9566878981  86.227544910  0.2510937270  8.0397667885  3600          0.5364471769 
0.9993898719  0.9682151589  0.8224946695  0.8589743590  1.0000000000  0.9850299401  0.9987277354  0.9579617834  93.413173652  0.2723798397  8.0397667885  3900          0.5321841184 
1.0000000000  0.9706601467  0.8160980810  0.8440170940  1.0000000000  0.9820359281  0.9977735369  0.9566878981  100.59880239  0.2891069946  8.0397667885  4200          0.5331767329 
Best model upto now
1.0000000000  0.9828850856  0.8411513859  0.8461538462  1.0000000000  0.9940119760  0.9980916031  0.9681528662  107.78443113  0.3180006679  8.0397667885  4500          0.5414549669 
0.9993898719  0.9608801956  0.7974413646  0.8290598291  1.0000000000  0.9910179641  0.9965012723  0.9643312102  114.97005988  0.2758753349  8.0397667885  4800          0.5711178819 
1.0000000000  0.9706601467  0.8464818763  0.8611111111  1.0000000000  0.9910179641  0.9996819338  0.9719745223  119.76047904  0.2601104363  8.0397667885  5000          0.5954670238 
