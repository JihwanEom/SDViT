Environment:
	Python: 3.8.13
	PyTorch: 1.8.1+cu111
	Torchvision: 0.9.1+cu111
	CUDA: 11.1
	CUDNN: 8005
	NumPy: 1.23.3
	PIL: 9.2.0
Args:
	algorithm: ERM_SDViT
	checkpoint_freq: None
	data_dir: ./domainbed/data/
	dataset: TerraIncognita
	holdout_fraction: 0.2
	hparams: {"backbone":"DeitSmall","batch_size":32,"lr":5e-05,"resnet_dropout":0.0,"weight_decay":0.0,"EMA":"True","CutMix":"True"}
	hparams_seed: 0
	output_dir: ./domainbed/TerraIncognita/ERM_SDViT_ours/ERM_SDViT_ours_DeiT-small/EMA_CutMix/228e8eb9b7147fb123358c25d6583d7c
	save_best_model: True
	save_model_every_checkpoint: False
	seed: 563577720
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [2]
	trial_seed: 1
	uda_holdout_fraction: 0
HParams:
	CutMix: True
	EMA: True
	EMA_decay: 0.999
	KL_Div_Temperature: 3.0
	RB_loss_weight: 0.5
	backbone: DeitSmall
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 5e-05
	nonlinear_classifier: False
	resnet18: False
	resnet_dropout: 0.0
	test_env: [2]
	weight_decay: 0.0
device: cuda
/local_ssd2/jeom/SDViT/domainbed/algorithms.py:275: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)
  t_param.data.mul_(self.ema_decay).add_(1 - self.ema_decay, s_param.data)
Best model upto now
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  epoch         loss          mem_gb        step          step_time    
0.0371737411  0.0327004219  0.0490435229  0.0508474576  0.1435768262  0.1397984887  0.1147227533  0.0926870748  0.0000000000  2.7231400013  7.8689751625  0             2.5349905491 
Best model upto now
0.5839704719  0.6118143460  0.4986519451  0.5023112481  0.2065491184  0.2052896725  0.3320586361  0.3086734694  3.0226700252  1.1472336379  8.1179423332  300           0.7164106242 
Best model upto now
0.7516477722  0.7637130802  0.6929002439  0.6923472008  0.3542191436  0.3715365239  0.5833864457  0.5663265306  6.0453400504  0.8908040650  8.1194834709  600           0.6857803162 
Best model upto now
0.8383865015  0.8554852321  0.7785338298  0.7760657422  0.4886649874  0.4848866499  0.7140429148  0.6743197279  9.0680100756  0.8104077193  8.1206431389  900           0.6952284567 
Best model upto now
0.8934880042  0.8839662447  0.8295031455  0.8258859784  0.5418765743  0.5314861461  0.7864882091  0.7414965986  12.090680100  0.8019185746  8.1206431389  1200          0.6370301477 
Best model upto now
0.9267070920  0.9156118143  0.8601874438  0.8495120699  0.5604534005  0.5516372796  0.8192054387  0.7653061224  15.113350125  0.7397230459  8.1206431389  1500          0.6879990443 
Best model upto now
0.9459530714  0.9261603376  0.8843240467  0.8669748331  0.5661209068  0.5604534005  0.8487359252  0.7942176871  18.136020151  0.7031795258  8.1206431389  1800          0.7164929597 
Best model upto now
0.9588716056  0.9398734177  0.8940813968  0.8808423215  0.5648614610  0.5604534005  0.8680688337  0.8248299320  21.158690176  0.6585900431  8.1206431389  2100          0.7360012539 
Best model upto now
0.9651990509  0.9462025316  0.9055077674  0.8844375963  0.5683249370  0.5629722922  0.8912258339  0.8375850340  24.181360201  0.6508099865  8.1206431389  2400          0.7465671825 
Best model upto now
0.9709992091  0.9493670886  0.9150083451  0.9003595275  0.5705289673  0.5629722922  0.8990864670  0.8469387755  27.204030226  0.6492666598  8.1206431389  2700          0.7773083258 
Best model upto now
0.9749538624  0.9504219409  0.9245089228  0.9019003595  0.5768261965  0.5629722922  0.9058848523  0.8596938776  30.226700251  0.6258269626  8.1206431389  3000          0.7851032297 
Best model upto now
0.9767993673  0.9546413502  0.9309282321  0.9080636877  0.5651763224  0.5579345088  0.9205438708  0.8698979592  33.249370277  0.6004912920  8.1206431389  3300          0.7818286355 
Best model upto now
0.9810176641  0.9609704641  0.9365772243  0.9080636877  0.5610831234  0.5554156171  0.9222434672  0.8801020408  36.272040302  0.5880656781  8.1206431389  3600          0.7849226594 
Best model upto now
0.9815449512  0.9567510549  0.9449223264  0.9203903441  0.5601385390  0.5667506297  0.9320161462  0.8775510204  39.294710327  0.5334082973  8.1206431389  3900          0.8088609680 
Best model upto now
0.9839177432  0.9620253165  0.9506997047  0.9131997946  0.5516372796  0.5642317380  0.9328659443  0.8835034014  42.317380352  0.5670572490  8.1206431389  4200          0.8295793748 
Best model upto now
0.9857632481  0.9630801688  0.9519835666  0.9239856189  0.5500629723  0.5654911839  0.9354153389  0.8869047619  45.340050377  0.5777661804  8.1206431389  4500          0.7421794526 
Best model upto now
0.9857632481  0.9651898734  0.9610989857  0.9337442219  0.5510075567  0.5667506297  0.9428510729  0.8894557823  48.362720403  0.5513052408  8.1206431389  4800          0.7159880686 
Best model upto now
0.9849723174  0.9651898734  0.9572474002  0.9393939394  0.5544710327  0.5680100756  0.9428510729  0.8911564626  50.377833753  0.5616816507  8.1214060783  5000          0.7033311737 
