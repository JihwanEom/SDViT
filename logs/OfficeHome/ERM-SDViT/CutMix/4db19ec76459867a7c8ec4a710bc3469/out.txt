Environment:
	Python: 3.8.13
	PyTorch: 1.8.1+cu111
	Torchvision: 0.9.1+cu111
	CUDA: 11.1
	CUDNN: 8005
	NumPy: 1.23.3
	PIL: 9.2.0
Args:
	algorithm: ERM_SDViT
	checkpoint_freq: None
	data_dir: ./domainbed/data/
	dataset: OfficeHome
	holdout_fraction: 0.2
	hparams: {"backbone":"DeitSmall","batch_size":32,"lr":5e-05,"resnet_dropout":0.0,"weight_decay":0.0,"CutMix":"True"}
	hparams_seed: 0
	output_dir: ./domainbed/OfficeHome/ERM_SDViT_ours/ERM_SDViT_ours_DeiT-small/CutMix/4db19ec76459867a7c8ec4a710bc3469
	save_best_model: True
	save_model_every_checkpoint: False
	seed: 640734081
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [3]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	CutMix: True
	EMA: False
	EMA_decay: 0.999
	KL_Div_Temperature: 3.0
	RB_loss_weight: 0.5
	backbone: DeitSmall
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 5e-05
	nonlinear_classifier: False
	resnet18: False
	resnet_dropout: 0.0
	test_env: [3]
	weight_decay: 0.0
device: cuda
Best model upto now
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  epoch         loss          mem_gb        step          step_time    
0.0175077240  0.0082474227  0.0194730813  0.0148911798  0.0171734234  0.0157835400  0.0203671830  0.0241102181  0.0000000000  4.3638978004  7.7882575989  0             4.1931636333 
Best model upto now
0.9057672503  0.7958762887  0.8361970218  0.7216494845  0.9194819820  0.8680947012  0.8100975330  0.8140068886  4.9433573635  1.9497195730  8.0360569954  300           0.4009082548 
Best model upto now
0.9721936148  0.7979381443  0.9109392898  0.7731958763  0.9586148649  0.8928974070  0.8215720023  0.8392652124  9.8867147271  1.0142171039  8.0360569954  600           0.4185947164 
Best model upto now
0.9881565396  0.8144329897  0.9438717068  0.7926689576  0.9777590090  0.9086809470  0.8258749283  0.8518943743  14.830072090  0.8883419794  8.0377049446  900           0.6247231682 
0.9912461380  0.8123711340  0.9616265750  0.8018327606  0.9864864865  0.8996617813  0.8318990247  0.8381171068  19.773429454  0.7723876258  8.0377049446  1200          0.7539996703 
Best model upto now
0.9933058702  0.8082474227  0.9707903780  0.8029782360  0.9862049550  0.9064261556  0.8333333333  0.8507462687  24.716786817  0.7083177397  8.0377049446  1500          0.7768690840 
Best model upto now
0.9948506694  0.8268041237  0.9739404353  0.8178694158  0.9918355856  0.9233370913  0.8296041308  0.8404133180  29.660144181  0.6170516657  8.0377049446  1800          0.7802689576 
0.9974253347  0.8020618557  0.9773768614  0.7938144330  0.9938063063  0.9267192785  0.8227194492  0.8358208955  34.603501544  0.7016713225  8.0377049446  2100          0.8058591564 
0.9958805355  0.8123711340  0.9813860252  0.8201603666  0.9938063063  0.9188275085  0.8278829604  0.8587830080  39.546858908  0.5723204184  8.0377049446  2400          0.8096451394 
0.9953656025  0.8226804124  0.9810996564  0.8213058419  0.9926801802  0.9188275085  0.8258749283  0.8450057405  44.490216271  0.5897181558  8.0377049446  2700          0.8173717753 
0.9953656025  0.8164948454  0.9816723940  0.8178694158  0.9949324324  0.9109357384  0.8304647160  0.8404133180  49.433573635  0.5683585285  8.0377049446  3000          0.8256969873 
0.9948506694  0.8185567010  0.9813860252  0.8144329897  0.9949324324  0.9086809470  0.8321858864  0.8323765786  54.376930999  0.5420667325  8.0377049446  3300          0.8265871843 
0.9948506694  0.8123711340  0.9839633448  0.8213058419  0.9963400901  0.9177001127  0.8364888124  0.8358208955  59.320288362  0.5664130867  8.0377049446  3600          0.8391092634 
0.9963954686  0.8268041237  0.9842497136  0.8167239404  0.9949324324  0.9210822999  0.8324727481  0.8300803674  64.263645726  0.5276675611  8.0377049446  3900          0.8275435368 
0.9963954686  0.8103092784  0.9831042383  0.8258877434  0.9960585586  0.9075535513  0.8275960987  0.8266360505  69.207003089  0.4979218279  8.0377049446  4200          0.8078334037 
0.9963954686  0.8247422680  0.9868270332  0.8178694158  0.9963400901  0.9131905299  0.8083763626  0.8128587830  74.150360453  0.5492931423  8.0377049446  4500          0.8366186428 
0.9969104016  0.8164948454  0.9836769759  0.8121420389  0.9969031532  0.9131905299  0.8273092369  0.8174512055  79.093717816  0.5028504511  8.0377049446  4800          0.7944082483 
0.9963954686  0.8164948454  0.9868270332  0.8155784651  0.9966216216  0.9278466742  0.8307515777  0.8163030999  82.389289392  0.5387169015  8.0377049446  5000          0.6887920976 
