Environment:
	Python: 3.8.13
	PyTorch: 1.8.1+cu111
	Torchvision: 0.9.1+cu111
	CUDA: 11.1
	CUDNN: 8005
	NumPy: 1.23.3
	PIL: 9.2.0
Args:
	algorithm: ERM_SDViT
	checkpoint_freq: None
	data_dir: ./domainbed/data/
	dataset: VLCS
	holdout_fraction: 0.2
	hparams: {"backbone":"DeitSmall","batch_size":32,"lr":5e-05,"resnet_dropout":0.0,"weight_decay":0.0,"CutMix":"True"}
	hparams_seed: 0
	output_dir: ./domainbed/VLCS/ERM_SDViT_ours/ERM_SDViT_ours_DeiT-small/CutMix/d6212361e90dbad76a3dabc88839da20
	save_best_model: True
	save_model_every_checkpoint: False
	seed: 306735527
	skip_model_save: False
	steps: None
	task: domain_generalization
	test_envs: [0]
	trial_seed: 0
	uda_holdout_fraction: 0
HParams:
	CutMix: True
	EMA: False
	EMA_decay: 0.999
	KL_Div_Temperature: 3.0
	RB_loss_weight: 0.5
	backbone: DeitSmall
	batch_size: 32
	class_balanced: False
	data_augmentation: True
	lr: 5e-05
	nonlinear_classifier: False
	resnet18: False
	resnet_dropout: 0.0
	test_env: [0]
	weight_decay: 0.0
device: cuda
Best model upto now
env0_in_acc   env0_out_acc  env1_in_acc   env1_out_acc  env2_in_acc   env2_out_acc  env3_in_acc   env3_out_acc  epoch         loss          mem_gb        step          step_time    
0.5141342756  0.4699646643  0.4974117647  0.5291902072  0.3194973343  0.3201219512  0.3554239171  0.3348148148  0.0000000000  1.5630170107  7.7879123688  0             1.6298692226 
Best model upto now
0.9452296820  0.9399293286  0.8291764706  0.7909604520  0.8880426504  0.8170731707  0.9266938171  0.8711111111  8.4805653710  0.7298829926  8.0368142128  300           0.7867489092 
Best model upto now
0.9584805654  0.9646643110  0.8842352941  0.7928436911  0.9421172887  0.8246951220  0.9577934098  0.8814814815  16.961130742  0.6016535007  8.0383858681  600           0.8095113969 
Best model upto now
0.9531802120  0.9752650177  0.9242352941  0.8041431262  0.9680121858  0.8338414634  0.9777860052  0.8770370370  25.441696113  0.5057439681  8.0383858681  900           0.8103160524 
0.9787985866  0.9717314488  0.9501176471  0.7702448211  0.9767707540  0.8216463415  0.9881525361  0.8755555556  33.922261484  0.4842822118  8.0398049355  1200          0.8395783552 
0.9708480565  0.9752650177  0.9698823529  0.7909604520  0.9832444783  0.8109756098  0.9907441688  0.8785185185  42.402826855  0.4657504310  8.0398049355  1500          0.8241850543 
0.9832155477  0.9787985866  0.9760000000  0.7645951036  0.9855293222  0.8064024390  0.9907441688  0.8814814815  50.883392226  0.4340640780  8.0398049355  1800          0.8644606384 
0.9849823322  0.9787985866  0.9821176471  0.7834274953  0.9950495050  0.7911585366  0.9940762680  0.8533333333  59.363957597  0.4174483163  8.0398049355  2100          0.8221565930 
0.9628975265  0.9681978799  0.9877647059  0.7721280603  0.9950495050  0.8170731707  0.9948167345  0.8681481481  67.844522968  0.3880654357  8.0398049355  2400          0.8033285578 
0.9717314488  0.9681978799  0.9882352941  0.7702448211  0.9969535415  0.8064024390  0.9974083673  0.8592592593  76.325088339  0.3562401178  8.0398049355  2700          0.8122415884 
0.9770318021  0.9646643110  0.9952941176  0.7683615819  0.9954303123  0.8003048780  0.9981488338  0.8681481481  84.805653710  0.3604346544  8.0398049355  3000          0.7813010232 
0.9779151943  0.9717314488  0.9971764706  0.7871939736  0.9954303123  0.8048780488  0.9985190670  0.8725925926  93.286219081  0.3972892837  8.0398049355  3300          0.7832926114 
0.9796819788  0.9823321555  0.9971764706  0.7871939736  0.9984767708  0.7926829268  0.9974083673  0.8637037037  101.76678445  0.3706380603  8.0398049355  3600          0.7963961307 
0.9796819788  0.9681978799  0.9967058824  0.7721280603  0.9977151561  0.8064024390  0.9988893003  0.8548148148  110.24734982  0.3725390061  8.0398049355  3900          0.8046820394 
0.9743816254  0.9681978799  0.9896470588  0.7683615819  0.9920030465  0.7926829268  0.9977786005  0.8770370370  118.72791519  0.3721130280  8.0398049355  4200          0.8463563848 
0.9787985866  0.9752650177  0.9962352941  0.7834274953  0.9969535415  0.8140243902  0.9992595335  0.8666666667  127.20848056  0.3809210084  8.0398049355  4500          0.7607792902 
0.9717314488  0.9752650177  0.9971764706  0.7645951036  0.9988575781  0.8064024390  0.9985190670  0.8666666667  135.68904593  0.3485814537  8.0398049355  4800          0.7586996229 
0.9761484099  0.9787985866  0.9943529412  0.7815442561  0.9996191927  0.7972560976  0.9985190670  0.8637037037  141.34275618  0.3546974013  8.0398049355  5000          0.7678889978 
